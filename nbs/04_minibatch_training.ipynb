{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import tensor,nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_close\n",
    "\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "path_data = Path('data')\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, 10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will need to compute the softmax of our activations. This is defined by:\n",
    "\n",
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
    "\n",
    "or more concisely:\n",
    "\n",
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum\\limits_{0 \\leq j \\lt n} e^{x_{j}}}$$ \n",
    "\n",
    "In practice, we will need the log of the softmax when we calculate the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the formula \n",
    "\n",
    "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$ \n",
    "\n",
    "gives a simplification when we compute the log softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the [LogSumExp trick](https://en.wikipedia.org/wiki/LogSumExp). The idea is to use the following formula:\n",
    "\n",
    "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
    "\n",
    "where a is the maximum of the $x_{j}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    m = x.max(-1)[0]\n",
    "    return m + (x-m[:,None]).exp().sum(-1).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we will avoid an overflow when taking the exponential of a big activation. In PyTorch, this is already implemented for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.37, -2.49, -2.36,  ..., -2.31, -2.28, -2.22],\n",
       "        [-2.37, -2.44, -2.44,  ..., -2.27, -2.26, -2.16],\n",
       "        [-2.48, -2.33, -2.28,  ..., -2.30, -2.30, -2.27],\n",
       "        ...,\n",
       "        [-2.33, -2.52, -2.34,  ..., -2.31, -2.21, -2.16],\n",
       "        [-2.38, -2.38, -2.33,  ..., -2.29, -2.26, -2.17],\n",
       "        [-2.33, -2.55, -2.36,  ..., -2.29, -2.27, -2.16]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_close(logsumexp(pred), pred.logsumexp(-1))\n",
    "sm_pred = log_softmax(pred)\n",
    "sm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
    "\n",
    "$$ -\\sum x\\, \\log p(x) $$\n",
    "\n",
    "But since our $x$s are 1-hot encoded (actually, they're just the integer indices), this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target.\n",
    "\n",
    "This can be done using numpy-style [integer array indexing](https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html#integer-array-indexing). Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.20, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.37, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.36, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[0,5],sm_pred[1,0],sm_pred[2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.20, -2.37, -2.36], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_pred[[0,1,2], y_train[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use PyTorch's implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.nll_loss(F.log_softmax(pred, -1), y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, `F.log_softmax` and `F.nll_loss` are combined in one optimized function, `F.cross_entropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(F.cross_entropy(pred, y_train), loss, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "F.log_softmax(\n",
       "    input: torch.Tensor,\n",
       "    dim: Optional[int] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    _stacklevel: int = \u001b[32m3\u001b[39m,\n",
       "    dtype: Optional[int] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       ") -> torch.Tensor\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Apply a softmax followed by a logarithm.\n",
       "\n",
       "While mathematically equivalent to log(softmax(x)), doing these two\n",
       "operations separately is slower and numerically unstable. This function\n",
       "uses an alternative formulation to compute the output and gradient correctly.\n",
       "\n",
       "See :class:`~torch.nn.LogSoftmax` for more details.\n",
       "\n",
       "Args:\n",
       "    input (Tensor): input\n",
       "    dim (int): A dimension along which log_softmax will be computed.\n",
       "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
       "      If specified, the input tensor is cast to :attr:`dtype` before the operation\n",
       "      is performed. This is useful for preventing data type overflows. Default: None.\n",
       "\u001b[31mFile:\u001b[39m      /nix/store/4g6fdiami8frg1xlxkgr935fpadiphh9-ml-env/lib/python3.13/site-packages/torch/nn/functional.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "F.log_softmax?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically the training loop repeats over the following steps:\n",
    "- get the output of the model on a batch of inputs\n",
    "- compare the output to the labels we have and compute a loss\n",
    "- calculate the gradients of the loss with respect to every parameter of the model\n",
    "- update said parameters with those gradients to make them a little bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.09, -0.21, -0.08,  0.10, -0.04,  0.08, -0.04, -0.03,  0.01,  0.06], grad_fn=<SelectBackward0>),\n",
       " torch.Size([50, 10]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=50                  # batch size\n",
    "\n",
    "xb = x_train[0:bs]     # a mini-batch from x\n",
    "preds = model(xb)      # predictions\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
       "        3, 9, 8, 5, 9, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 9, 3, 8, 5, 9, 3, 9, 3, 9, 5, 3, 9, 9, 3, 9, 9, 5, 8, 7, 9, 5, 3, 8, 9, 5, 9, 5, 5, 9, 3, 5, 9, 7, 5, 7, 9, 9, 3, 9, 3, 5, 3, 8,\n",
       "        3, 5, 9, 5, 9, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def accuracy(out, yb): return (out.argmax(dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.08)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5   # learning rate\n",
    "epochs = 3 # how many epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def report(loss, preds, yb): print(f'{loss:.2f}, {accuracy(preds, yb):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.30, 0.08\n"
     ]
    }
   ],
   "source": [
    "xb,yb = x_train[:bs],y_train[:bs]\n",
    "preds = model(xb)\n",
    "report(loss_func(preds, yb), preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11, 0.96\n",
      "0.13, 0.96\n",
      "0.12, 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n,i+bs))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias   -= l.bias.grad   * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias  .grad.zero_()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using parameters and optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3,4)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_children at 0x7f0448d23140>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.named_children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.57,  0.43, -0.30],\n",
       "         [ 0.13, -0.32, -0.24],\n",
       "         [ 0.51,  0.04,  0.22],\n",
       "         [ 0.13, -0.17, -0.24]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.01, -0.51, -0.39,  0.56], requires_grad=True)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x): return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(m, nh, 10)\n",
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "for name,l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            s = slice(i, min(n,i+bs))\n",
    "            xb,yb = x_train[s],y_train[s]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19, 0.96\n",
      "0.11, 0.96\n",
      "0.04, 1.00\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, PyTorch overrides the `__setattr__` function in `nn.Module` so that the submodules you define are properly registered as parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "\n",
    "    def __setattr__(self,k,v):\n",
    "        if not k.startswith(\"_\"): self._modules[k] = v\n",
    "        super().__setattr__(k,v)\n",
    "\n",
    "    def __repr__(self): return f'{self._modules}'\n",
    "    \n",
    "    def parameters(self):\n",
    "        for l in self._modules.values(): yield from l.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = MyModule(m,nh,10)\n",
    "mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in mdl.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the original `layers` approach, but we have to register the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "\n",
    "    def forward(self, x): return reduce(lambda val,layer: layer(val), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 10])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.ModuleList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.ModuleList` does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SequentialModel(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.96\n",
      "0.11, 0.96\n",
      "0.07, 0.98\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Sequential` is a convenient class which does the same as the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16, 0.94\n",
      "0.13, 0.96\n",
      "0.08, 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.03, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params: p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.params: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18, 0.94\n",
      "0.13, 0.96\n",
      "0.11, 0.94\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n,i+bs))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch already provides this exact functionality in `optim.SGD` (it also handles stuff like momentum, which we'll look at later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.33, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.98\n",
      "0.09, 0.98\n",
      "0.07, 0.98\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(n,i+bs))\n",
    "        xb,yb = x_train[s],y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clunky to iterate through minibatches of x and y values separately:\n",
    "\n",
    "```python\n",
    "    xb = x_train[s]\n",
    "    yb = y_train[s]\n",
    "```\n",
    "\n",
    "Instead, let's do these two steps together, by introducing a `Dataset` class:\n",
    "\n",
    "```python\n",
    "    xb,yb = train_ds[s]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "assert len(train_ds)==len(x_train)\n",
    "assert len(valid_ds)==len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = train_ds[0:5]\n",
    "assert xb.shape==(5,28*28)\n",
    "assert yb.shape==(5,)\n",
    "xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17, 0.96\n",
      "0.11, 0.94\n",
      "0.09, 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        xb,yb = train_ds[i:min(n,i+bs)]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, our loop iterated over batches (xb, yb) like this:\n",
    "\n",
    "```python\n",
    "for i in range(0, n, bs):\n",
    "    xb,yb = train_ds[i:min(n,i+bs)]\n",
    "    ...\n",
    "```\n",
    "\n",
    "Let's make our loop much cleaner, using a data loader:\n",
    "\n",
    "```python\n",
    "for xb,yb in train_dl:\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): self.ds,self.bs = ds,bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 6, 9, 6, 4, 5, 3, 8, 4, 5, 2, 3, 8, 4, 8, 1, 5, 0, 5, 9, 7, 4, 1, 0, 3, 0, 6, 2, 9, 9, 4, 1, 3, 6, 8, 0, 7, 7, 6, 8, 9, 0, 3,\n",
       "        8, 3, 7, 7, 8, 4])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(loss, preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11, 0.98\n",
      "0.09, 0.98\n",
      "0.06, 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.03, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, shuffle=False): self.n,self.shuffle = len(ds),shuffle\n",
    "    def __iter__(self):\n",
    "        res = list(range(self.n))\n",
    "        if self.shuffle: random.shuffle(res)\n",
    "        return iter(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Sampler(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "it = iter(ss)\n",
    "for o in range(5): print(next(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30599, 42052, 40919, 23757, 41990]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = Sampler(train_ds, shuffle=True)\n",
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler():\n",
    "    def __init__(self, sampler, bs, drop_last=False): fc.store_attr()\n",
    "    def __iter__(self): yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m fc.chunked(it, chunk_sz=\u001b[38;5;28;01mNone\u001b[39;00m, drop_last=\u001b[38;5;28;01mFalse\u001b[39;00m, n_chunks=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
       "\u001b[31mSource:\u001b[39m   \n",
       "\u001b[38;5;28;01mdef\u001b[39;00m chunked(it, chunk_sz=\u001b[38;5;28;01mNone\u001b[39;00m, drop_last=\u001b[38;5;28;01mFalse\u001b[39;00m, n_chunks=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
       "    \u001b[33m\"Return batches from iterator `it` of size `chunk_sz` (or return `n_chunks` total)\"\u001b[39m\n",
       "    \u001b[38;5;28;01massert\u001b[39;00m bool(chunk_sz) ^ bool(n_chunks)\n",
       "    \u001b[38;5;28;01mif\u001b[39;00m n_chunks: chunk_sz = max(math.ceil(len(it)/n_chunks), \u001b[32m1\u001b[39m)\n",
       "    \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(it, Iterator): it = iter(it)\n",
       "    \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
       "        res = list(itertools.islice(it, chunk_sz))\n",
       "        \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;28;01mand\u001b[39;00m (len(res)==chunk_sz \u001b[38;5;28;01mor\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m drop_last): \u001b[38;5;28;01myield\u001b[39;00m res\n",
       "        \u001b[38;5;28;01mif\u001b[39;00m len(res)<chunk_sz: \u001b[38;5;28;01mreturn\u001b[39;00m\n",
       "\u001b[31mFile:\u001b[39m      /nix/store/4g6fdiami8frg1xlxkgr935fpadiphh9-ml-env/lib/python3.13/site-packages/fastcore/basics.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fc.chunked??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15644, 30522, 23044, 30213],\n",
       " [36727, 14968, 3341, 49577],\n",
       " [31834, 39753, 15165, 32183],\n",
       " [27591, 29191, 32486, 4157],\n",
       " [34542, 32971, 30124, 22104]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchs = BatchSampler(ss, 4)\n",
    "list(islice(batchs, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return torch.stack(xs),torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True ), bs)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12, 0.96\n",
      "0.03, 1.00\n",
      "0.15, 0.94\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "from fastcore.basics import store_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[3,6,8,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([1, 1, 1, 0]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.__getitem__([3,6,8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 1]))\n",
      "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "for o in map(train_ds.__getitem__, ([3,6],[8,1])): print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batchs, n_workers=1, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        with mp.Pool(self.n_workers) as ex: yield from ex.map(self.ds.__getitem__, iter(self.batchs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp, n_workers=2)\n",
    "it = iter(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = next(it)\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(RandomSampler(train_ds),     bs, drop_last=False)\n",
    "valid_samp = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_sampler=train_samp, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_samp, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10, 0.94\n",
      "0.10, 0.96\n",
      "0.27, 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.05, grad_fn=<NllLossBackward0>), tensor(0.98))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch can auto-generate the BatchSampler for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch can also generate the Sequential/RandomSamplers too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True, num_workers=2)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21, 0.92\n",
      "0.15, 0.94\n",
      "0.05, 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.01, grad_fn=<NllLossBackward0>), tensor(1.))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset actually already knows how to sample a batch of indices all at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([9, 1, 3]))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[4,6,7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...that means that we can actually skip the batch_sampler and collate_fn entirely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, sampler=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, sampler=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 50, 784]), torch.Size([1, 50]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You **always** should also have a [validation set](http://www.fast.ai/2017/11/13/validation-sets/), in order to identify if you are overfitting.\n",
    "\n",
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb,yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc,count = 0.,0.,0\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                n = len(xb)\n",
    "                count += n\n",
    "                tot_loss += loss_func(pred,yb).item()*n\n",
    "                tot_acc  += accuracy (pred,yb).item()*n\n",
    "        print(epoch, tot_loss/count, tot_acc/count)\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.14236384081654252 0.958100004196167\n",
      "1 0.12564024755731226 0.9632000041007995\n",
      "2 0.1306914782896638 0.9645000052452087\n",
      "3 0.10988454953534528 0.9670000064373017\n",
      "4 0.11636367190163582 0.9678000068664551\n",
      "CPU times: user 19.6 s, sys: 32.4 ms, total: 19.6 s\n",
      "Wall time: 4.94 s\n"
     ]
    }
   ],
   "source": [
    "%time loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
